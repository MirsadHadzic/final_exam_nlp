{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d063338-8518-420a-a356-88d6eea9ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f004f24-8db9-4dd2-bd5e-9e25453b1c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK resources\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "65d32231-88b0-4c4e-9aec-ad1bbcc59a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Lenovo/Downloads/movie_reviews (1).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218854cc-a284-4d0b-91a1-2801ce922359",
   "metadata": {},
   "source": [
    "Question 1: Data Analysis and Preprocessing (25 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "375d7d53-0038-4608-b9a1-3847186d06ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  40000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3496d116-5f69-474f-97a3-184e969b9c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Dsitribution\n",
      "label\n",
      "0    20019\n",
      "1    19981\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display class distribution\n",
    "print(\"\\nClass Dsitribution\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cd596aa8-70f9-4d4d-a6d2-49494bfc0475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of                                                     text  label\n",
      "0      I grew up (b. 1965) watching and loving the Th...      0\n",
      "1      When I put this movie in my DVD player, and sa...      0\n",
      "2      Why do people who do not know what a particula...      0\n",
      "3      Even though I have great interest in Biblical ...      0\n",
      "4      Im a die hard Dads Army fan and nothing will e...      1\n",
      "...                                                  ...    ...\n",
      "39995  \"Western Union\" is something of a forgotten cl...      1\n",
      "39996  This movie is an incredible piece of work. It ...      1\n",
      "39997  My wife and I watched this movie because we pl...      0\n",
      "39998  When I first watched Flatliners, I was amazed....      1\n",
      "39999  Why would this film be so good, but only gross...      1\n",
      "\n",
      "[40000 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "31725384-29cc-4922-aacf-c526fd6bfbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Positive Reviews Examples:\n",
      "label\n",
      "0    20019\n",
      "1    19981\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "negative    20019\n",
      "positive    19981\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Positive Reviews Examples:\n",
      "4    Im a die hard Dads Army fan and nothing will e...\n",
      "6    Finally watched this shocking movie last night...\n",
      "Name: text, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show 2 examples from each class\n",
    "print(\"\\nPositive Reviews Examples:\")\n",
    "# print(df[df['label'] == '1']['text'].head(4), \"\\n\")\n",
    "# First, map them to human-readable form (optional but useful)\n",
    "print(df['label'].value_counts())\n",
    "df['label'] = df['label'].map({1: 'positive', 0: 'negative'})\n",
    "\n",
    "# Then run:\n",
    "print(df['label'].value_counts())\n",
    "print(\"\\nPositive Reviews Examples:\")\n",
    "print(df[df['label'] == 'positive']['text'].head(2), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eeced022-213a-43db-ba42-7b27e2efda38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_4204\\3239145654.py:16: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_cleaned = df.applymap(remove_illegal_chars)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from openpyxl.utils.exceptions import IllegalCharacterError\n",
    "\n",
    "# Define illegal character pattern\n",
    "def remove_illegal_chars(text):\n",
    "    if isinstance(text, str):\n",
    "        # Remove characters not allowed in Excel (except for newline and tab)\n",
    "        return re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f]', '', text)\n",
    "    return text\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csvdf = pd.read_csv(\"C:/Users/Lenovo/Downloads/movie_reviews (1).csv\", on_bad_lines='skip')\n",
    "\n",
    "# Apply cleanup to all cells\n",
    "df_cleaned = df.applymap(remove_illegal_chars)\n",
    "\n",
    "# Save to Excel\n",
    "df_cleaned.to_excel(\"C:/Users/Lenovo/Downloads/movie_reviews_cleaned.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5b82c733-796c-4f88-b17f-6fe7a728d0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Text Length by Class:\n",
      "label\n",
      "negative    229.204606\n",
      "positive    233.477954\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate average text length for each class\n",
    "df['text_length'] = df['text'].apply(lambda x: len(x.split()))\n",
    "print(\"\\nAverage Text Length by Class:\")\n",
    "print(df.groupby('label')['text_length'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9df504c8-a348-4abe-8557-9f670e2988ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>grew b watching loving thunderbirds mates scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>put movie dvd player sat coke chips expectatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>people know particular time past like feel nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>even though great interest biblical movies bor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>im die hard dads army fan nothing ever change ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  I grew up (b. 1965) watching and loving the Th...   \n",
       "1  When I put this movie in my DVD player, and sa...   \n",
       "2  Why do people who do not know what a particula...   \n",
       "3  Even though I have great interest in Biblical ...   \n",
       "4  Im a die hard Dads Army fan and nothing will e...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  grew b watching loving thunderbirds mates scho...  \n",
       "1  put movie dvd player sat coke chips expectatio...  \n",
       "2  people know particular time past like feel nee...  \n",
       "3  even though great interest biblical movies bor...  \n",
       "4  im die hard dads army fan nothing ever change ...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.2 Basic Preprocessing (15 pts)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"processed_text\"] = df['text'].apply(preprocess)\n",
    "df[['text', 'processed_text']].head(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b23c2d-1588-42ec-91af-79db45a5ee50",
   "metadata": {},
   "source": [
    "2.1 Apply VADER Analysis (20 pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "783ee6d5-35d9-4c00-ab9b-a1105a4f827c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>compound</th>\n",
       "      <th>vader_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0.6502</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0.9314</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>-0.9568</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>-0.7515</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>0.7469</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  compound  \\\n",
       "0  I grew up (b. 1965) watching and loving the Th...    0.6502   \n",
       "1  When I put this movie in my DVD player, and sa...    0.9314   \n",
       "2  Why do people who do not know what a particula...   -0.9568   \n",
       "3  Even though I have great interest in Biblical ...   -0.7515   \n",
       "4  Im a die hard Dads Army fan and nothing will e...    0.7469   \n",
       "\n",
       "  vader_prediction  \n",
       "0         positive  \n",
       "1         positive  \n",
       "2         negative  \n",
       "3         negative  \n",
       "4         positive  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize VADER\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Get compound scores\n",
    "df['compound'] = df['text'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "\n",
    "# Convert to binary label: positive if compound > 0\n",
    "df['vader_prediction'] = df['compound'].apply(lambda x: 'positive' if x > 0 else 'negative')\n",
    "\n",
    "# Show a few results\n",
    "df[['text', 'compound', 'vader_prediction']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "29606ee0-0cc0-4ca4-8a68-39c55c756d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER Evaluation:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.54      0.64     20019\n",
      "    positive       0.65      0.86      0.74     19981\n",
      "\n",
      "    accuracy                           0.70     40000\n",
      "   macro avg       0.72      0.70      0.69     40000\n",
      "weighted avg       0.72      0.70      0.69     40000\n",
      "\n",
      "Confusion Matrix: \n",
      "[[10765  9254]\n",
      " [ 2889 17092]]\n"
     ]
    }
   ],
   "source": [
    "print(\"VADER Evaluation:\\n\")\n",
    "print(classification_report(df['label'], df['vader_prediction']))\n",
    "\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(df['label'], df['vader_prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b8a2ae72-2407-4eba-b6a9-fae5fac1c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Machine Learning Implementation (35 pts)\n",
    "\n",
    "# 3.1 Feature Extraction \n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(df['processed_text'])\n",
    "\n",
    "# Labels\n",
    "y = df['label']\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8c3d596e-d001-43d5-9a84-28bbec84c7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Evaluation:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.83      3966\n",
      "    positive       0.83      0.85      0.84      4034\n",
      "\n",
      "    accuracy                           0.84      8000\n",
      "   macro avg       0.84      0.84      0.84      8000\n",
      "weighted avg       0.84      0.84      0.84      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Train and Evaluate Classifier (20 pts)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Naive Bayes Evaluation:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3a12d4fb-a442-443c-9c36-7c54e8f2c8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[3278  688]\n",
      " [ 622 3412]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab79a1e4-5850-45c6-b8a6-b8c494aadb77",
   "metadata": {},
   "source": [
    "Question 4: Comparison and Analysis (10 pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9c21ee2a-7e0d-4a06-bf65-b1c2b9b5cdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison table: \n",
      "         Model  Accuracy  Precision    Recall\n",
      "0        VADER  0.696425   0.648751  0.855413\n",
      "1  Naive Bayes  0.836250   0.832195  0.845811\n"
     ]
    }
   ],
   "source": [
    "# Comparison table\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# VADER metrics\n",
    "vader_acc = accuracy_score(df['label'], df['vader_prediction'])\n",
    "vader_prec = precision_score(df['label'], df['vader_prediction'], pos_label = 'positive')\n",
    "vader_rec = recall_score(df['label'], df['vader_prediction'], pos_label = 'positive')\n",
    "\n",
    "# NB metrics\n",
    "nb_acc = accuracy_score(y_test, y_pred)\n",
    "nb_prec = precision_score(y_test, y_pred, pos_label = 'positive')\n",
    "nb_rec = recall_score(y_test, y_pred, pos_label = 'positive')\n",
    "\n",
    "# Create comparison tabel\n",
    "comparison = pd.DataFrame({\n",
    "    'Model' : [\"VADER\", \"Naive Bayes\"],\n",
    "    \"Accuracy\" : [vader_acc, nb_acc],\n",
    "    'Precision': [vader_prec, nb_prec],\n",
    "    'Recall': [vader_rec, nb_rec]\n",
    "})\n",
    "\n",
    "print(\"\\nComparison table: \")\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8ed33e28-3c2f-4630-9196-42c5989980d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Critical Analysis (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9927554d-a42e-44f3-9765-b658a063b611",
   "metadata": {},
   "source": [
    "VADER:\n",
    "+ Advantage: Pre-trained and works well on social media or informal text.\n",
    "- Disadvantage: May miss domain-specific context and nuances in longer reviews.\n",
    "\n",
    "Naive Bayes:\n",
    "+ Advantage: Learns from data, can capture domain-specific patterns.\n",
    "- Disadvantage: Requires preprocessing and training, and performance depends on data quality.\n",
    "\n",
    "For a production system, I would choose the Naive Bayes approach due to its better adaptability to the specific dataset and the potential for improvement with more data and tuning. VADER is great for quick prototyping, but ML models offer more control and customizability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "458c2786-98af-49d4-beba-97d8e0d83f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'positive']\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].unique())\n",
    "print(df['label'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb3ac2-9d3a-45ea-9cd6-3df359ff7c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
